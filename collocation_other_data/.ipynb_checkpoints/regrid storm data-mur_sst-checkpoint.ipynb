{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset  # http://code.google.com/p/netcdf4-python/\n",
    "import os\n",
    "dir_in='f:/data/tc_wakes/database/info/'\n",
    "dir_out='f:/data/tc_wakes/database/sst/'\n",
    "#################################################################################\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "#from datetime import datetime\n",
    "import pandas\n",
    "import matplotlib as mpl\n",
    "#import openpyxl\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "#from math import cos, radians\n",
    "from netCDF4 import Dataset  # http://code.google.com/p/netcdf4-python/\n",
    "import os\n",
    "####################you will need to change some paths here!#####################\n",
    "#list of input files\n",
    "dir_in='f:/data/tc_wakes/database/info/'\n",
    "dir_out='f:/data/tc_wakes/database/sat_data/'\n",
    "dir_mur = 'F:/data/sst/jpl_mur/v4.1/'\n",
    "#output files\n",
    "#filename_out_nc='F:/data/cruise_data/saildrone/baja-2018/daily_files/sd-1002/data_so_far.nc'\n",
    "#filename_out_kml='F:/data/cruise_data/saildrone/baja-2018/daily_files/sd-1002/data_so_far.kml'\n",
    "#################################################################################\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import matplotlib as mpl\n",
    "#import openpyxl\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "#from math import cos, radians\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.mlab as mlab\n",
    "palette = copy(plt.cm.jet)\n",
    "palette.set_over('r', 1.0)\n",
    "palette.set_under('g', 1.0)\n",
    "palette.set_bad(alpha = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in target lat/lon (ccmp array)\n",
    "ccmp_filename='F:/data/sat_data/ccmp/v02.0/Y2003/M10/CCMP_Wind_Analysis_20031009_V02.0_L3.0_RSS.nc'\n",
    "ds_target=xr.open_dataset(ccmp_filename)  #don't need nobs\n",
    "ds_target_lon=ds_target.longitude\n",
    "ds_target_lat=ds_target.latitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001annual_storm_info.nc f:/data/tc_wakes/database/info/2004\\001annual_storm_info.nc\n",
      "(26,)\n",
      "271 277 56.299998585134745 74.3999984934926 -13.999999843537807 2.8000000938773155\n",
      "F:/data/sst/jpl_mur/v4.1/2003/266/20030923090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n"
     ]
    }
   ],
   "source": [
    "dir_ccmp='F:/data/sat_data/ccmp/v02.0/Y'\n",
    "date_1858 = dt.datetime(1858,11,17,0,0,0) # start date is 11/17/1958\n",
    "dx=0.25\n",
    "dy=0.25\n",
    "dx_offset = -179.875\n",
    "dy_offset = 78.3750\n",
    "for root, dirs, files in os.walk(dir_in, topdown=False):\n",
    "    #print(files)\n",
    "    #for ii in range(40,90): \n",
    "    #print(root[31:35])\n",
    "    for name in files:\n",
    "        istart_storm=0\n",
    "        #name = files[ii]\n",
    "        fname_in=os.path.join(root, name)\n",
    "        print(name,fname_in)\n",
    "        dsx = xr.open_dataset(fname_in)\n",
    "        lats = dsx.lat[0,:]\n",
    "        lons = dsx.lon[0,:]\n",
    "        dysince = dsx.time\n",
    "        icycle=0\n",
    "        minlon=min(lons.values)-7\n",
    "        maxlon=max(lons.values)+7\n",
    "        minlat=min(lats.values)-7\n",
    "        maxlat=max(lats.values)+7\n",
    "        if minlon<10. and maxlon>350.:  #wrapping around meridion need to cal new min/max lon\n",
    "            minlon=max(lons[lons<180].values)+7\n",
    "            maxlon=min(lons[lons>180].values)-7\n",
    "            icycle=1 #set flag for wraparound\n",
    "        dims=lats.shape\n",
    "        print(dims)\n",
    "        tdim=dims[0]\n",
    "        tem_date=[0]*tdim #print(dysince.values)\n",
    "        for i in range(0,tdim):\n",
    "            tem_date[i]=date_1858+dt.timedelta(days=float(dysince[0,i].values))  #create new time array that can be queried for year etc\n",
    "        minjdy = min(tem_date).timetuple().tm_yday  #create new time array that can be queried for year etc\n",
    "        minyear =min(tem_date).year #create new time array that can be queried for year etc\n",
    "        maxjdy = max(tem_date).timetuple().tm_yday  #create new time array that can be queried for year etc\n",
    "        maxyear =max(tem_date).year  #create new time array that can be queried for year etc\n",
    "        dif = max(tem_date)-min(tem_date)\n",
    "        tdim=int(dif.days)  \n",
    "        print(minjdy,maxjdy,minlon,maxlon,minlat,maxlat)\n",
    "        ds_new=[]\n",
    "        new_coord=[]\n",
    "        for incr_dy in range(-5,tdim+25): #from -5 to 25 days after\n",
    "            storm_date = tem_date[0]+dt.timedelta(days=incr_dy)            \n",
    "            #print(storm_date)\n",
    "            syr=str(storm_date.year)\n",
    "            smon=str(storm_date.month)\n",
    "            sdym=str(storm_date.day)\n",
    "            sjdy=str(storm_date.timetuple().tm_yday)\n",
    "            fname_tem=syr + smon.zfill(2) + sdym.zfill(2) + '090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc'\n",
    "            mur_filename = dir_mur + syr + '/' + sjdy.zfill(3) + '/' + fname_tem\n",
    "            print(mur_filename)\n",
    "            ds=xr.open_dataset(mur_filename,drop_variables=('analysis_error','sea_ice_fraction'))  #don't need nobs\n",
    "            ds_rolled = ds.assign_coords(lon=(ds.lon % 360)).roll(lon=(ds.dims['lon'] // 2))\n",
    "            sst=ds_rolled.analysed_sst\n",
    "            #interpolate 1 km mur data onto CCMP grid\n",
    "            sst_interp = sst.interp(lat=ds_target_lat,lon=ds_target_lon)\n",
    "            #select lat/lon region\n",
    "            if icycle==0:\n",
    "                ds2=sst_interp.sel(latitude=slice(minlat,maxlat),longitude=slice(minlon,maxlon))\n",
    "            else:\n",
    "                ds2=sst_interp.sel(latitude=slice(minlat,maxlat),longitude=(sst_interp.longitude < minlon) | (sst_interp.longitude > maxlon))\n",
    "            #print(ds2)\n",
    "            ds_new.append(ds2)\n",
    "            new_coord.append(storm_date)\n",
    "        combined = xr.concat(ds_new, dim='time')\n",
    "        combined.coords['time'] = new_coord\n",
    "        fname_out=dir_out + 'mur' + root[31:35] + name[0:3] + '.nc'\n",
    "        print(fname_out)\n",
    "        combined.to_netcdf(fname_out)\n",
    "        #break\n",
    "    #break\n",
    "#print(ds_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:       (lat: 17999, lon: 36000, time: 1)\n",
       "Coordinates:\n",
       "  * time          (time) datetime64[ns] 2003-09-23T09:00:00\n",
       "  * lat           (lat) float32 -89.99 -89.98 -89.97 -89.96 -89.95 -89.94 ...\n",
       "  * lon           (lon) float32 -179.99 -179.98 -179.97 -179.96 -179.95 ...\n",
       "Data variables:\n",
       "    analysed_sst  (time, lat, lon) float32 ...\n",
       "    mask          (time, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    comment:                    MUR = \"Multi-scale Ultra-high Reolution\"\n",
       "    license:                    These data are available free of charge under...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    naming_authority:           org.ghrsst\n",
       "    product_version:            04.1\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    gds_version_id:             2.0\n",
       "    netcdf_version_id:          4.1\n",
       "    date_created:               20150817T233507Z\n",
       "    start_time:                 20030923T090000Z\n",
       "    stop_time:                  20030923T090000Z\n",
       "    time_coverage_start:        20030922T210000Z\n",
       "    time_coverage_end:          20030923T210000Z\n",
       "    file_quality_level:         1\n",
       "    source:                     AMSRE-REMSS, AVHRR_Pathfinder-PFV5.2-NODC_day...\n",
       "    platform:                   Aqua, DMSP, NOAA-POES, Suomi-NPP, Terra\n",
       "    sensor:                     AMSR-E, AVHRR, MODIS, SSM/I, VIIRS, in-situ\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    keywords:                   Oceans > Ocean Temperature > Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    southernmost_latitude:      -90.0\n",
       "    northernmost_latitude:      90.0\n",
       "    westernmost_longitude:      -180.0\n",
       "    easternmost_longitude:      180.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    processing_level:           L4\n",
       "    cdm_data_type:              grid"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno -101] NetCDF: HDF error: b'f:\\\\data\\\\model_data\\\\gmao\\\\flux\\\\MERRA2_300.tavg1_2d_flx_Nx.20041114.SUB.nc4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b367d11efedf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f:/data/model_data/gmao/flux/MERRA2_300.tavg1_2d_flx_Nx.20041114.SUB.nc4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\backends\\api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m                                                    \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                                                    \u001b[0mautoclose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                                                    **backend_kwargs)\n\u001b[0m\u001b[0;32m    321\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'scipy'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             store = backends.ScipyDataStore(filename_or_obj,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\backends\\netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, filename, mode, format, group, writer, clobber, diskless, persist, autoclose, lock)\u001b[0m\n\u001b[0;32m    330\u001b[0m                                    \u001b[0mdiskless\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdiskless\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                                    format=format)\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m         return cls(ds, mode=mode, writer=writer, opener=opener,\n\u001b[0;32m    334\u001b[0m                    autoclose=autoclose, lock=lock)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\backends\\netCDF4_.py\u001b[0m in \u001b[0;36m_open_netcdf4_group\u001b[1;34m(filename, mode, group, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnc4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnc4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mnetCDF4\\_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnetCDF4\\_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno -101] NetCDF: HDF error: b'f:\\\\data\\\\model_data\\\\gmao\\\\flux\\\\MERRA2_300.tavg1_2d_flx_Nx.20041114.SUB.nc4'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "fname='f:/data/model_data/gmao/flux/MERRA2_300.tavg1_2d_flx_Nx.20041114.SUB.nc4'\n",
    "ds=xr.open_dataset(fname)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
