{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting and data analysis for global cold wakes\n",
    "#from netCDF4 import Dataset  # http://code.google.com/p/netcdf4-python/\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "####################you will need to change some paths here!#####################\n",
    "#list of input directories\n",
    "dir_storm_info='f:/data/tc_wakes/database/info/'\n",
    "dir_out='f:/data/tc_wakes/database/sst/'\n",
    "dir_flux = 'F:/data/model_data/oaflux/data_v3/daily/turbulence/'\n",
    "dir_cmc = 'F:/data/sst/cmc/CMC0.2deg/v2/'\n",
    "dir_ccmp='F:/data/sat_data/ccmp/v02.0/Y'\n",
    "##where to get the data through opendap, use these directories instead\n",
    "#dir_cmc = 'https://podaac-opendap.jpl.nasa.gov/opendap/allData/ghrsst/data/GDS2/L4/GLOB/CMC/CMC0.1deg/v3/'\n",
    "#dir_flux = 'http://apdrc.soest.hawaii.edu:80/dods/public_data/WHOI_OAFlux/version3/daily/lh_oaflux/'\n",
    "#the latest ccmp is from www.remss.com but they do not have an opendap server so you can use this instead:\n",
    "#dir_ccmp='https://podaac-opendap.jpl.nasa.gov/opendap/allData/ccmp/L3.0/flk/'\n",
    "\n",
    "#################################################################################\n",
    "import geopy.distance\n",
    "from math import sin, pi\n",
    "from scipy import interpolate\n",
    "\n",
    "#functions for running storm data\n",
    "import sys\n",
    "#sys.path.append('C:/Users/gentemann/Google Drive/d_drive/python/storm_heat_content/subroutines/')\n",
    "#from storm_masking_routines import interpolate_storm_path\n",
    "#from storm_masking_routines import get_dist_grid\n",
    "#from storm_masking_routines import closest_dist\n",
    "#from storm_masking_routines import calculate_storm_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot output data and mask\n",
    "\n",
    "import os\n",
    "dir_out_figures = 'F:/data/tc_wakes/database/figs/check_storm_dist/'\n",
    "iyr_storm,inum_storm = 2003,27\n",
    "for inum_storm in range(1,58): #100):\n",
    "    filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_interpolated_track.nc'\n",
    "    exists = os.path.isfile(filename)\n",
    "    if not exists:\n",
    "        continue\n",
    "    print(filename)\n",
    "    ds_storm=xr.open_dataset(filename)\n",
    "    ds_storm = ds_storm.sel(j2=0)\n",
    "    ds_storm.close()\n",
    "#    ds_storm['lon'] = (ds_storm.lon + 180) % 360 - 180\n",
    "    filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_combined_data.nc'\n",
    "    ds_all = xr.open_dataset(filename)\n",
    "    ds_all.close()\n",
    "    #ds_all = ds_all.sortby('lon')\n",
    "    print(ds_all.lon[0].values,ds_all.lon[-1].values)\n",
    "    if abs(ds_all.lon[-1]-ds_all.lon[0])>180:\n",
    "        ds_all.coords['lon'] = np.mod(ds_all['lon'], 360)\n",
    "        #ds_all = ds_all.sortby(ds_all.lon)\n",
    "        ds_storm['lon'] = np.mod(ds_storm['lon'], 360)\n",
    "        #ds_storm = ds_storm.sortby(ds_storm.lon)\n",
    "    plt.figure(figsize=(15,3.5))\n",
    "    plt.subplot(131)\n",
    "    ds_all.side_of_storm.plot()\n",
    "    plt.plot(ds_storm.lon,ds_storm.lat,'w')\n",
    "    plt.plot(ds_storm.lon[0],ds_storm.lat[0],'w*')\n",
    "    plt.subplot(132)\n",
    "    ds_all.dist_from_storm_km.plot(vmin=0,vmax=3000)\n",
    "    plt.plot(ds_storm.lon,ds_storm.lat,'w')\n",
    "    max_lat = ds_storm.lat.max()\n",
    "    if max_lat<0:\n",
    "        cond = ((ds_all.dist_from_storm_km<100) & (ds_all.side_of_storm<=0)) |  ((ds_all.dist_from_storm_km<800) & (ds_all.side_of_storm>0))\n",
    "    else:\n",
    "        cond = ((ds_all.dist_from_storm_km<800) & (ds_all.side_of_storm<0)) |  ((ds_all.dist_from_storm_km<100) & (ds_all.side_of_storm>=0))\n",
    "    subset = ds_all.where(cond)\n",
    "    plt.subplot(133)\n",
    "    subset.dist_from_storm_km.plot(vmin=0,vmax=3000)\n",
    "    plt.plot(ds_storm.lon,ds_storm.lat,'w')\n",
    "    filename = dir_out_figures + str(iyr_storm) + str(inum_storm).zfill(3) + '_interpolated_track.png'\n",
    "    plt.savefig(filename,dpi=100,bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum7=np.zeros(50)\n",
    "print(sum7[0],sum7[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:/data/tc_wakes/database/sst/2003/065_interpolated_track.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gentemann\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py:749: FutureWarning: Default reduction dimension will be changed to the grouped dimension after xarray 0.12. To silence this warning, pass dim=xarray.ALL_DIMS explicitly.\n",
      "  allow_lazy=True, **kwargs)\n",
      "C:\\Users\\gentemann\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py:755: FutureWarning: Default reduction dimension will be changed to the grouped dimension after xarray 0.12. To silence this warning, pass dim=xarray.ALL_DIMS explicitly.\n",
      "  **kwargs)\n",
      "C:\\Users\\gentemann\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py:749: FutureWarning: Default reduction dimension will be changed to the grouped dimension after xarray 0.12. To silence this warning, pass dim=xarray.ALL_DIMS explicitly.\n",
      "  allow_lazy=True, **kwargs)\n",
      "C:\\Users\\gentemann\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py:755: FutureWarning: Default reduction dimension will be changed to the grouped dimension after xarray 0.12. To silence this warning, pass dim=xarray.ALL_DIMS explicitly.\n",
      "  **kwargs)\n",
      "C:\\Users\\gentemann\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py:749: FutureWarning: Default reduction dimension will be changed to the grouped dimension after xarray 0.12. To silence this warning, pass dim=xarray.ALL_DIMS explicitly.\n",
      "  allow_lazy=True, **kwargs)\n",
      "C:\\Users\\gentemann\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py:755: FutureWarning: Default reduction dimension will be changed to the grouped dimension after xarray 0.12. To silence this warning, pass dim=xarray.ALL_DIMS explicitly.\n",
      "  **kwargs)\n",
      "C:\\Users\\gentemann\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py:749: FutureWarning: Default reduction dimension will be changed to the grouped dimension after xarray 0.12. To silence this warning, pass dim=xarray.ALL_DIMS explicitly.\n",
      "  allow_lazy=True, **kwargs)\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-046e362e87fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0msubset_cnt3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby_bins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'coldwake_dytorecovery'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcbin3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#sums variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mcbin4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#mld\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0msubset_sum4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby_bins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dbss_obml'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcbin4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#sums number\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[0msubset_cnt4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby_bins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dbss_obml'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcbin4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#sums variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mcbin5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#mld\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[1;34m(self, dim, skipna, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m                 return self.reduce(func, dim,\n\u001b[0;32m    748\u001b[0m                                    \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m                                    allow_lazy=True, **kwargs)\n\u001b[0m\u001b[0;32m    750\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m             def wrapped_func(self, dim=DEFAULT_DIMS,\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, func, dim, keep_attrs, **kwargs)\u001b[0m\n\u001b[0;32m    736\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mreduce_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_attrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[1;31m# TODO remove the following class method and DEFAULT_DIMS after the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, args, **kwargs)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shortcut'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ignore shortcut if set (for now)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_grouped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_combine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapplied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\groupby.py\u001b[0m in \u001b[0;36m_combine\u001b[1;34m(self, applied)\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_combine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapplied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;34m\"\"\"Recombine the applied objects like the original.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mapplied_example\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpeek_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m         \u001b[0mcoord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_concat_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied_example\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\utils.py\u001b[0m in \u001b[0;36mpeek_at\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \"\"\"\n\u001b[0;32m    139\u001b[0m     \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#plotting and data analysis for global cold wakes\n",
    "#from netCDF4 import Dataset  # http://code.google.com/p/netcdf4-python/\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import geopy.distance\n",
    "from math import sin, pi\n",
    "from scipy import interpolate\n",
    "\n",
    "#functions for running storm data\n",
    "import sys\n",
    "\n",
    "####################you will need to change some paths here!#####################\n",
    "#list of input directories\n",
    "dir_storm_info='f:/data/tc_wakes/database/info/'\n",
    "dir_out='f:/data/tc_wakes/database/sst/'\n",
    "#################################################################################\n",
    "\n",
    "#start to look at data and make some pdfs\n",
    "\n",
    "date_1858 = dt.datetime(1858,11,17,0,0,0) # start date is 11/17/1958\n",
    "\n",
    "#init arrays\n",
    "init_data=0\n",
    "num1=np.zeros([101,101,201,101])\n",
    "sum1=np.zeros([101,101,201,101])\n",
    "num2=np.zeros([101,101,201,101])\n",
    "sum2=np.zeros([101,101,201,101])\n",
    "num3=np.zeros(101)\n",
    "num4=np.zeros(101)\n",
    "num5=np.zeros(101)\n",
    "sum5=np.zeros(101)\n",
    "num6=np.zeros(101)\n",
    "sum6=np.zeros(101)\n",
    "sum7=np.zeros(101)\n",
    "num7=np.zeros(101)\n",
    "dim1,dim2,dim3,dim4,dim5,dim6,dim7,dim8=np.zeros(101),np.zeros(101),np.zeros(101),np.zeros(101),np.zeros(101),np.zeros(201),np.zeros(101),np.zeros(101)\n",
    "\n",
    "map_lats=np.arange(-90,90,.25)\n",
    "map_lons=np.arange(-180,180,.25)\n",
    "imap_lats = map_lats.size\n",
    "imap_lons = map_lons.size\n",
    "map_sum,map_cnt,map_max = np.zeros([imap_lats,imap_lons]),np.zeros([imap_lats,imap_lons]),np.zeros([imap_lats,imap_lons])\n",
    "  \n",
    "iyr_storm = 2003\n",
    "for inum_storm in range(65,66): #(0,100): #100):\n",
    "    filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_interpolated_track.nc'\n",
    "    exists = os.path.isfile(filename)\n",
    "    if not exists:\n",
    "        continue\n",
    "    print(filename)\n",
    "    ds_storm_info=xr.open_dataset(filename)\n",
    "    ds_storm_info = ds_storm_info.sel(j2=0)\n",
    "    ds_storm_info.close()\n",
    "    filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_combined_data_all.nc'\n",
    "    ds_all = xr.open_dataset(filename)\n",
    "    ds_all['spd']=np.sqrt(ds_all.uwnd**2+ds_all.vwnd**2)\n",
    "    ds_all.close()\n",
    "    if abs(ds_all.lon[-1]-ds_all.lon[0])>180:\n",
    "        ds_all.coords['lon'] = np.mod(ds_all['lon'], 360)\n",
    "        ds_storm_info['lon'] = np.mod(ds_storm_info['lon'], 360)\n",
    "    max_lat = ds_storm_info.lat.max()\n",
    "    #remove all data outsice 100km/800km or cold wake >0 or <-10\n",
    "    if max_lat<0:\n",
    "        cond = ((((ds_all.dist_from_storm_km<100) & (ds_all.side_of_storm<=0)) | \n",
    "        ((ds_all.dist_from_storm_km<800) & (ds_all.side_of_storm>0))) \n",
    "        & (ds_all.coldwake_max<=0) & (ds_all.coldwake_max>=-10))\n",
    "    else:\n",
    "        cond = ((((ds_all.dist_from_storm_km<800) & (ds_all.side_of_storm<0)) | \n",
    "        ((ds_all.dist_from_storm_km<100) & (ds_all.side_of_storm>=0))) \n",
    "        & (ds_all.coldwake_max<=0) & (ds_all.coldwake_max>=-10))\n",
    "    subset = ds_all.where(cond)\n",
    "\n",
    "    xdim,ydim,tdim = ds_all.lon.shape[0],ds_all.lat.shape[0],ds_all.time.shape[0]\n",
    "    \n",
    "    #change hr to recovery to day to recovery\n",
    "    subset['coldwake_dytorecovery'] = subset.coldwake_hrtorecovery/24.\n",
    "    \n",
    "    #calculate the historgram and mean for the cold wakes\n",
    "    cbin1 = np.arange(-10, 0, 0.1)  #cold wake bins\n",
    "    subset_sum1=subset.groupby_bins('coldwake_max',cbin1).sum()  #sums number\n",
    "    subset_cnt1=subset.groupby_bins('coldwake_max',cbin1).count()    #sums variable  \n",
    "    cbin2 = np.arange(0,24*6)  #hour to max\n",
    "    subset_sum2=subset.groupby_bins('coldwake_hrtomaxcold',cbin2).sum()  #sums number\n",
    "    subset_cnt2=subset.groupby_bins('coldwake_hrtomaxcold',cbin2).count()    #sums variable\n",
    "    cbin3 = np.arange(0,50)  #dy to recovery\n",
    "    subset_sum3=subset.groupby_bins('coldwake_dytorecovery',cbin3).sum()  #sums number\n",
    "    subset_cnt3=subset.groupby_bins('coldwake_dytorecovery',cbin3).count()    #sums variable\n",
    "    cbin4 = np.arange(0,500)  #mld\n",
    "    subset_sum4=subset.groupby_bins('dbss_obml',cbin4).sum()  #sums number\n",
    "    subset_cnt4=subset.groupby_bins('dbss_obml',cbin4).count()    #sums variable\n",
    "    cbin5 = np.arange(0,200)  #mld\n",
    "    subset_sum5=subset.groupby_bins('spd',cbin5).sum()  #sums number\n",
    "    subset_cnt5=subset.groupby_bins('spd',cbin5).count()    #sums variable\n",
    "\n",
    "    sdate = np.empty([ydim,xdim], dtype=dt.datetime)    \n",
    "    for i in range(0,xdim):\n",
    "        for j in range(0,ydim):\n",
    "            sdate[j,i] = np.datetime64(date_1858 + dt.timedelta(days=float(ds_all.closest_storm_time[j,i])))\n",
    "    #xsdate=xr.DataArray(sdate, coords={'lat': ds_data.lat.values, 'lon':ds_data.lon.values}, dims=('lat', 'lon'))        \n",
    "    sdate2 = np.empty([tdim,ydim,xdim])    \n",
    "    for i in range(0,xdim):\n",
    "        for j in range(0,ydim):\n",
    "            if np.isnan(subset.analysed_sst[0,j,i]):  #don't process masked values\n",
    "                continue\n",
    "            for k in range(0,tdim):\n",
    "                sdate2[k,j,i] = (ds_all.time[k] - sdate[j,i]) / np.timedelta64(1,'D')\n",
    "    xsdate2=xr.DataArray(sdate2, coords={'time':ds_all.time, 'lat': ds_all.lat.values, 'lon':ds_all.lon.values}, dims=('time','lat', 'lon'))        \n",
    "    ds_all['dys_from_storm2']=xsdate2\n",
    "    cbin6 = np.arange(-10,50,1)  #cold wake bins\n",
    "    subset_sum6=ds_all.groupby_bins('dys_from_storm2',cbin6).sum()  #sums number\n",
    "    subset_cnt6=ds_all.groupby_bins('dys_from_storm2',cbin6).count()    #sums variable  \n",
    "\n",
    "        #start saving this data\n",
    "    if init_data == 0:\n",
    "        sv_sum1,sv_cnt1 = subset_sum1,subset_cnt1\n",
    "        sv_sum2,sv_cnt2 = subset_sum2,subset_cnt2\n",
    "        sv_sum3,sv_cnt3 = subset_sum3,subset_cnt3\n",
    "        sv_sum4,sv_cnt4 = subset_sum4,subset_cnt4\n",
    "        sv_sum5,sv_cnt5 = subset_sum5,subset_cnt5\n",
    "        sv_sum6,sv_cnt6 = subset_sum6,subset_cnt6\n",
    "        init_data=1\n",
    "    else:\n",
    "        sv_sum1+= subset_sum1\n",
    "        sv_cnt1+= subset_cnt1\n",
    "        sv_sum2+= subset_sum2\n",
    "        sv_cnt2+= subset_cnt2\n",
    "        sv_sum3+= subset_sum3\n",
    "        sv_cnt3+= subset_cnt3\n",
    "        sv_sum4+= subset_sum4\n",
    "        sv_cnt4+= subset_cnt4\n",
    "        sv_sum5+= subset_sum5\n",
    "        sv_cnt5+= subset_cnt5      \n",
    "        sv_sum6+= subset_sum6\n",
    "        sv_cnt6+= subset_cnt6           \n",
    "\n",
    "        #put on global map\n",
    "    tem = subset.coldwake_max.interp(lat=map_lats,lon=map_lons)\n",
    "    tem=tem.fillna(0)\n",
    "    temc=(tem/tem).fillna(0)\n",
    "    map_sum+=tem\n",
    "    map_cnt+=temc\n",
    "    map_max=np.where(tem.data < map_max, tem,map_max)  #where tem<max put tem value in otherwise leave max\n",
    "        \n",
    "    for i in range(0,xdim):\n",
    "        for j in range(0,ydim):\n",
    "            if np.isnan(subset.analysed_sst[0,j,i]):  #don't process masked values\n",
    "                continue\n",
    "            storm_date64 = np.datetime64(date_1858 + dt.timedelta(days=float(ds_all.closest_storm_time[j,i])))\n",
    "            time_diff = subset.time-storm_date64\n",
    "            storm_index = np.argmin(abs(time_diff)).data\n",
    "\n",
    "#            map_sum[j,i]+=subset.coldwake_max[j,i]\n",
    "#            map_cnt[j,i]+=1\n",
    "#            if  map_max[j,i]>subset.coldwake_max[j,i]:\n",
    "#                map_max[j,i]=subset.coldwake_max[j,i]\n",
    "            \n",
    "            if subset.coldwake_max[j,i]<-0.1:  #cold wake larger than -0.1 \n",
    "                icold=int(np.round(subset.coldwake_max[j,i].data*10.))+10\n",
    "                icoldhr=int(np.round(subset.coldwake_hrtomaxcold[j,i].data))\n",
    "                icolddy2=int(np.round(subset.coldwake_hrtorecovery[j,i].data/24.))\n",
    "                iswnd=int(np.round(subset.wmo_storm_wind[j,i].data*.5))\n",
    "                iwnd=int(np.round(subset.spd[storm_index,j,i].data))\n",
    "                isspd=int(abs(np.round(subset.wmo_storm_speed[j,i].data)))\n",
    "\n",
    "            #PROBLEM MLD interpolation pre 1/1 for each year need to fix\n",
    "            #for now just setting first data to 1/1 for each year\n",
    "                im=0\n",
    "                if np.isnan(subset.dbss_obml[im,j,i].data):\n",
    "                    while np.isnan(subset.dbss_obml[im,j,i].data):\n",
    "                        im+=1\n",
    "                        if im>=tdim:\n",
    "                            break\n",
    "                if im>=tdim:\n",
    "                    continue\n",
    "                if np.isnan(subset.dbss_obml[im,j,i].data):\n",
    "                    continue\n",
    "                imld=int(np.round(subset.dbss_obml[im,j,i].data))\n",
    "\n",
    "                if (icold<0) | (icold>100):  #cold wake max between 0,10 K\n",
    "                    continue\n",
    "                if (icold>=0) & (icold<=100) & (isspd>=0) & (isspd<=200) & (imld>=0) & (imld<=100):                \n",
    "                    if (iswnd>=0) & (iswnd<=100):             \n",
    "                        sum1[icold,iswnd,isspd,imld]=sum1[icold,iswnd,isspd,imld]+subset.coldwake_max[j,i].data  #uses storm wind from wmo track\n",
    "                        num1[icold,iswnd,isspd,imld]=num1[icold,iswnd,isspd,imld]+1  #uses storm wind from wmo track\n",
    "                    if (iwnd>=0) & (iwnd<=100):                  \n",
    "                        sum2[icold,iwnd,isspd,imld]=sum2[icold,iwnd,isspd,imld]+subset.coldwake_max[j,i].data    #uses collocated ccmp wind on storm day\n",
    "                        num2[icold,iwnd,isspd,imld]=num2[icold,iwnd,isspd,imld]+1    #uses collocated ccmp wind on storm day\n",
    " #               if (icoldhr>=0) & (icoldhr<100):\n",
    " #                   num3[icoldhr]=num3[icoldhr]+1   #pdf of when max cold wake occurs\n",
    " #               if (icolddy2>=0) & (icolddy2<100):\n",
    " #                   num4[icolddy2]=num4[icolddy2]+1   #pdf of when recovery occurs\n",
    "    #            num4[icold] = num4[icold]+1                     \n",
    " #               sum5[icold]=sum5[icold]+subset.coldwake_hrtorecovery[j,i].data  #mean of recorvery time as f(max coldwake)\n",
    " #               num5[icold]=num5[icold]+1  #mean of recorvery time as f(max coldwake)\n",
    " #               if (icoldhr>=0) & (icoldhr<100):\n",
    " #                   sum6[icoldhr]=sum6[icoldhr]+subset.coldwake_max[j,i].data  #mean of max cold wake as f(hr from storm)\n",
    " #                   num6[icoldhr]=num6[icoldhr]+1  #mean of max cold wake as f(hr from storm)\n",
    "\n",
    "                #caluclate the mean sst anomaly as f(days after storm)\n",
    " #               for k in range(storm_index,tdim):\n",
    " #                   data_time = subset.time[k]\n",
    " #                   dtime = data_time-storm_date64\n",
    " #                   ddy = dtime / np.timedelta64(1,'D')\n",
    " #                   iddy = int(np.round(ddy))\n",
    " #                   if (iddy<0) | (iddy>50):\n",
    " #                       continue\n",
    " #                   change_in_sst = subset.sst_prestorm[j,i].data-subset.analysed_sst[k,j,i].data\n",
    " #                   sum7[iddy]=sum7[iddy]+change_in_sst  \n",
    " #                   num7[iddy]=num7[iddy]+1  \n",
    "\n",
    "    for i in range(0,100):\n",
    "        dim1[i]=(i-10)/10\n",
    "        dim2[i]=i\n",
    "        dim3[i]=i*24\n",
    "        dim4[i]=i/.5\n",
    "        dim5[i]=i\n",
    "        dim7[i]=i\n",
    "        dim8[i]=i\n",
    "    for i in range(0,200):\n",
    "        dim6[i]=i\n",
    "#                                'num3': (('coldhr'),num3),\n",
    "#                                'num4': (('colddy'),num4),\n",
    "#                                'sum5': (('cold'),sum5),\n",
    "#                                'num5': (('cold'),num5),\n",
    "#                                'sum6': (('coldhr'),sum6),\n",
    "#                                'num6': (('coldhr'),num6),\n",
    "#                               'sum7': (('dyfrom'),sum7),\n",
    "#                                'num7': (('dyfrom'),num7)\n",
    " \n",
    "    m1=xr.DataArray(map_sum, coords={'lat': map_lats, 'lon':map_lons}, dims=('lat', 'lon'))        \n",
    "    m2=xr.DataArray(map_cnt, coords={'lat': map_lats, 'lon':map_lons}, dims=('lat', 'lon'))        \n",
    "    m3=xr.DataArray(map_max, coords={'lat': map_lats, 'lon':map_lons}, dims=('lat', 'lon'))        \n",
    "\n",
    "    ds=xr.Dataset(data_vars={'sum1': (('cold','swnd','sspd','mld'),sum1),\n",
    "                                'num1': (('cold','swnd','sspd','mld'),num1),\n",
    "                                'sum2': (('cold','cwnd','sspd','mld'),sum2),\n",
    "                                'num2': (('cold','cwnd','sspd','mld'),num2),\n",
    "                                'map_sum': (('lat','lon'),m1),\n",
    "                                'map_cnt': (('lat','lon'),m2),\n",
    "                                'map_max': (('lat','lon'),m3)\n",
    "                               },\n",
    "                                 coords={'cold':dim1,'coldhr':dim2,'colddy':dim3,'swnd':dim4,\n",
    "                                         'wnd':dim5,'sspd':dim6,'mld':dim7,'dyfrom':dim8,\n",
    "                                         'lat':map_lats,'lon':map_lons})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x710283c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#subset.spd.max('time').plot()\n",
    "#subset.coldwake_max.plot()\n",
    "subset.dbss_obml[20,:,:].plot()\n",
    "#subset.hum2m[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'time' (time: 53)>\n",
       "array(['2003-08-23T12:00:00.000000000', '2003-08-24T12:00:00.000000000',\n",
       "       '2003-08-25T12:00:00.000000000', '2003-08-26T12:00:00.000000000',\n",
       "       '2003-08-27T12:00:00.000000000', '2003-08-28T12:00:00.000000000',\n",
       "       '2003-08-29T12:00:00.000000000', '2003-08-30T12:00:00.000000000',\n",
       "       '2003-08-31T12:00:00.000000000', '2003-09-01T12:00:00.000000000',\n",
       "       '2003-09-02T12:00:00.000000000', '2003-09-03T12:00:00.000000000',\n",
       "       '2003-09-04T12:00:00.000000000', '2003-09-05T12:00:00.000000000',\n",
       "       '2003-09-06T12:00:00.000000000', '2003-09-07T12:00:00.000000000',\n",
       "       '2003-09-08T12:00:00.000000000', '2003-09-09T12:00:00.000000000',\n",
       "       '2003-09-10T12:00:00.000000000', '2003-09-11T12:00:00.000000000',\n",
       "       '2003-09-12T12:00:00.000000000', '2003-09-13T12:00:00.000000000',\n",
       "       '2003-09-14T12:00:00.000000000', '2003-09-15T12:00:00.000000000',\n",
       "       '2003-09-16T12:00:00.000000000', '2003-09-17T12:00:00.000000000',\n",
       "       '2003-09-18T12:00:00.000000000', '2003-09-19T12:00:00.000000000',\n",
       "       '2003-09-20T12:00:00.000000000', '2003-09-21T12:00:00.000000000',\n",
       "       '2003-09-22T12:00:00.000000000', '2003-09-23T12:00:00.000000000',\n",
       "       '2003-09-24T12:00:00.000000000', '2003-09-25T12:00:00.000000000',\n",
       "       '2003-09-26T12:00:00.000000000', '2003-09-27T12:00:00.000000000',\n",
       "       '2003-09-28T12:00:00.000000000', '2003-09-29T12:00:00.000000000',\n",
       "       '2003-09-30T12:00:00.000000000', '2003-10-01T12:00:00.000000000',\n",
       "       '2003-10-02T12:00:00.000000000', '2003-10-03T12:00:00.000000000',\n",
       "       '2003-10-04T12:00:00.000000000', '2003-10-05T12:00:00.000000000',\n",
       "       '2003-10-06T12:00:00.000000000', '2003-10-07T12:00:00.000000000',\n",
       "       '2003-10-08T12:00:00.000000000', '2003-10-09T12:00:00.000000000',\n",
       "       '2003-10-10T12:00:00.000000000', '2003-10-11T12:00:00.000000000',\n",
       "       '2003-10-12T12:00:00.000000000', '2003-10-13T12:00:00.000000000',\n",
       "       '2003-10-14T12:00:00.000000000'], dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2003-08-23T12:00:00 ... 2003-10-14T12:00:00"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if 10*(int(inum_storm/10))==inum_storm:\n",
    "        filename='f:/data/tc_wakes/database/results/pdf'+str(iyr_storm)+'.nc'\n",
    "        ds.to_netcdf(filename)\n",
    "        print('output file',inum_storm, filename)\n",
    "filename='f:/data/tc_wakes/database/results/pdf'+str(iyr_storm)+'.nc'\n",
    "ds.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/sum1'+str(iyr_storm)+'.nc'\n",
    "sv_sum1.coords['coldwake_max_bins'] = cbin1[0:-1]  # could also use assign_coords\n",
    "sv_sum1.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/cnt1'+str(iyr_storm)+'.nc'\n",
    "sv_cnt1.coords['coldwake_max_bins'] = cbin1[0:-1]  # could also use assign_coords\n",
    "sv_cnt1.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/sum2'+str(iyr_storm)+'.nc'\n",
    "sv_sum2.coords['coldwake_hrtomaxcold_bins'] = cbin2[0:-1]  # could also use assign_coords\n",
    "sv_sum2.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/cnt2'+str(iyr_storm)+'.nc'\n",
    "sv_cnt2.coords['coldwake_hrtomaxcold_bins'] = cbin2[0:-1]  # could also use assign_coords\n",
    "sv_cnt2.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/sum3'+str(iyr_storm)+'.nc'\n",
    "sv_sum3.coords['coldwake_dytorecovery_bins'] = cbin3[0:-1]  # could also use assign_coords\n",
    "sv_sum3.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/cnt3'+str(iyr_storm)+'.nc'\n",
    "sv_cnt3.coords['coldwake_dytorecovery_bins'] = cbin3[0:-1]  # could also use assign_coords\n",
    "sv_cnt3.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/sum4'+str(iyr_storm)+'.nc'\n",
    "sv_sum4.coords['dbss_obml_bins'] = cbin4[0:-1]  # could also use assign_coords\n",
    "sv_sum4.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/cnt4'+str(iyr_storm)+'.nc'\n",
    "sv_cnt4.coords['dbss_obml_bins'] = cbin4[0:-1]  # could also use assign_coords\n",
    "sv_cnt4.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/sum5'+str(iyr_storm)+'.nc'\n",
    "sv_sum5.coords['spd_bins'] = cbin5[0:-1]  # could also use assign_coords\n",
    "sv_sum5.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/cnt5'+str(iyr_storm)+'.nc'\n",
    "sv_cnt5.coords['spd_bins'] = cbin5[0:-1]  # could also use assign_coords\n",
    "sv_cnt5.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/sum6'+str(iyr_storm)+'.nc'\n",
    "sv_sum6.coords['dys_from_storm2_bins'] = cbin6[0:-1]  # could also use assign_coords\n",
    "sv_sum6.to_netcdf(filename)\n",
    "filename='f:/data/tc_wakes/database/results/cnt6'+str(iyr_storm)+'.nc'\n",
    "sv_cnt6.coords['dys_from_storm2_bins'] = cbin6[0:-1]  # could also use assign_coords\n",
    "sv_cnt6.to_netcdf(filename)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cbin1[0:-1],sv_cnt1.coldwake_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=xr.DataArray(sv_sum1, coords={'cbin1': cbin1}, dims=('cbin1'))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cbin1[0:-1],cwake_cnt1.coldwake_max)\n",
    "#subset.coldwake_dytorecovery[40:80,75]\n",
    "\n",
    "#subset.coldwake_hrtomaxcold[40:80,75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem=np.empty([ydim,xdim], dtype=dt.datetime)    \n",
    "for i in range(0,xdim):\n",
    "        for j in range(0,ydim):\n",
    "            tem[j,i] = np.datetime64(date_1858 + dt.timedelta(days=float(ds_all.closest_storm_time[j,i])))\n",
    "ds_all['closest_storm_time64']=xr.DataArray(tem, coords={'lat': ds_all.lat.values, 'lon':ds_all.lon.values}, dims=('lat', 'lon'))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all['closest_storm_time64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sum7/num7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbin = np.arange(-10, 0, 0.1)\n",
    "icold=subset.coldwake_max*10.+10\n",
    "#icoldhr=int(np.round(subset.coldwake_hrtomaxcold.data))\n",
    "#icolddy2=int(np.round(subset.coldwake_hrtorecovery.data/24.))\n",
    "#iswnd=int(np.round(subset.wmo_storm_wind.data*.5))\n",
    "#iwnd=int(np.round(subset.spd.data))\n",
    "#isspd=int(abs(np.round(subset.wmo_storm_speed.data)))\n",
    "m=subset.groupby_bins('coldwake_max',cbin).mean()   #calculates mean\n",
    "c=subset.groupby_bins('coldwake_max',cbin).count()  #sums number\n",
    "s=subset.groupby_bins('coldwake_max',cbin).sum()    #sums variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.coldwake_max[-2].values,s.coldwake_max[-2].values,c.coldwake_max[-2].values,s.coldwake_max[-2].values/c.coldwake_max[-2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iyr_storm = 2003\n",
    "filename='f:/data/tc_wakes/database/results/pdf'+str(iyr_storm)+'.nc'\n",
    "#plot the pdsf different ways\n",
    "ds = xr.open_dataset(filename)\n",
    "ds.close()\n",
    "ds\n",
    "ds.num7.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "from math import sin, pi\n",
    "import numpy as np\n",
    "#this routine takes a point and finds distance to all points in a grid of lat and lon\n",
    "#it is slowwwwwww\n",
    "tdim_storm = ds_storm_info.time.size\n",
    "storm_speed = ds_storm_info.time.copy(deep=True)*np.nan    \n",
    "for i in range(0,tdim_storm-1):\n",
    "    coords_1 = (ds_storm_info.lat[i], ds_storm_info.lon[i])  \n",
    "    coords_2 = (ds_storm_info.lat[i+1], ds_storm_info.lon[i+1])  \n",
    "    arclen_temp = geopy.distance.geodesic(coords_1, coords_2).km  #distance in km  \n",
    "    storm_date1 = np.datetime64(date_1858 + dt.timedelta(days=float(ds_storm_info.time[i])))  #create new time array that can be queried for year etc\n",
    "    storm_date2 = np.datetime64(date_1858 + dt.timedelta(days=float(ds_storm_info.time[i+1])))  #create new time array that can be queried for year etc\n",
    "    arclen_time = storm_date2 - storm_date1\n",
    "    arclen_hr = arclen_time / np.timedelta64(1, 'h')\n",
    "    storm_speed[i]=arclen_temp/(arclen_hr)\n",
    "storm_speed[-1]=storm_speed[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = xr.open_dataset(filename)\n",
    "ds_all['spd']=np.sqrt(ds_all.uwnd**2+ds_all.vwnd**2)\n",
    "ds_all.close()\n",
    "if abs(ds_all.lon[-1]-ds_all.lon[0])>180:\n",
    "    ds_all.coords['lon'] = np.mod(ds_all['lon'], 360)\n",
    "    ds_storm_info['lon'] = np.mod(ds_storm_info['lon'], 360)\n",
    "max_lat = ds_storm_info.lat.max()\n",
    "if max_lat<0:\n",
    "    cond = ((ds_all.dist_from_storm_km<100) & (ds_all.side_of_storm<=0)) |  ((ds_all.dist_from_storm_km<800) & (ds_all.side_of_storm>0))\n",
    "else:\n",
    "    cond = ((ds_all.dist_from_storm_km<800) & (ds_all.side_of_storm<0)) |  ((ds_all.dist_from_storm_km<100) & (ds_all.side_of_storm>=0))\n",
    "subset = ds_all.where(cond)\n",
    "#subset now only has the data within 100 and 800 km of storm\n",
    "xdim,ydim,tdim = ds_all.lon.shape[0],ds_all.lat.shape[0],ds_all.time.shape[0]\n",
    "date_1858 = dt.datetime(1858,11,17,0,0,0) # start date is 11/17/1958\n",
    "coldwake_max=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "coldwake_delay=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "for i in range(0,xdim):\n",
    "    for j in range(0,ydim):\n",
    "        storm_date = date_1858 + dt.timedelta(days=float(ds_all.closest_storm_time[j,i]))  #create new time array that can be queried for year etc\n",
    "        storm_date64 = np.datetime64(storm_date)\n",
    "        if np.isnan(subset.analysed_sst[0,j,i]):  #don't process masked values\n",
    "            continue\n",
    "        time_diff = subset.time-storm_date64\n",
    "        storm_index = np.argmin(abs(time_diff)).data\n",
    "        istart,iend = int(storm_index)-1,int(storm_index)+5\n",
    "        if istart<0:\n",
    "            istart=0\n",
    "        if iend>tdim:\n",
    "            iend=tdim\n",
    "        coldwake_max[j,i] = (subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i]).min()\n",
    "coldwake_max.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(subset.sst_prestorm-subset.analysed_sst[0,:,:]).plot()  cold wake\n",
    "xdim,ydim,tdim = ds_all.lon.shape[0],ds_all.lat.shape[0],ds_all.time.shape[0]\n",
    "date_1858 = dt.datetime(1858,11,17,0,0,0) # start date is 11/17/1958\n",
    "coldwake_max=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "coldwake_maxindex=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "coldwake_hrtomaxcold=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "coldwake_recovery=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "for i in range(0,xdim):\n",
    "    for j in range(0,ydim):\n",
    "        storm_date = date_1858 + dt.timedelta(days=float(ds_all.closest_storm_time[j,i]))  #create new time array that can be queried for year etc\n",
    "        storm_date64 = np.datetime64(storm_date)\n",
    "        if np.isnan(subset.analysed_sst[0,j,i]):  #don't process masked values\n",
    "            continue\n",
    "        time_diff = subset.time-storm_date64\n",
    "        storm_index = np.argmin(abs(time_diff)).data\n",
    "        istart,iend = int(storm_index)-1,int(storm_index)+5\n",
    "        if istart<0:\n",
    "            istart=0\n",
    "        if iend>tdim:\n",
    "            iend=tdim\n",
    "        coldwake_max[j,i] = (subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i]).min()\n",
    "        itmp = np.argmin(subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i]).data\n",
    "        coldwake_maxindex[j,i]=istart+itmp\n",
    "        delay = subset.time[istart+itmp].values-subset.time[istart+1].values\n",
    "        coldwake_hrtomaxcold[j,i]=delay / np.timedelta64(1, 'h')\n",
    "        for k in range(istart+itmp,tdim):\n",
    "            sst_change = subset.sst_prestorm[j,i]-subset.analysed_sst[k,j,i]\n",
    "            if sst_change>-0.2:\n",
    "                break\n",
    "        delay = subset.time[k].values-subset.time[istart+1].values\n",
    "        coldwake_recovery[j,i]=delay / np.timedelta64(1, 'h')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = 100,100\n",
    "coldwake_max=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "coldwake_maxindex=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "coldwake_hrtomaxcold=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "coldwake_recovery=ds_all.sst_prestorm.copy(deep=True)*np.nan\n",
    "storm_date = date_1858 + dt.timedelta(days=float(ds_all.closest_storm_time[j,i]))  #create new time array that can be queried for year etc\n",
    "storm_date64 = np.datetime64(storm_date)\n",
    "time_diff = subset.time-storm_date64\n",
    "storm_index = np.argmin(abs(time_diff)).data\n",
    "istart,iend = int(storm_index)-1,int(storm_index)+5\n",
    "if istart<0:\n",
    "    istart=0\n",
    "if iend>tdim:\n",
    "    iend=tdim\n",
    "coldwake_max[j,i] = (subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i]).min()\n",
    "itmp = np.argmin(subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i]).data\n",
    "coldwake_maxindex[j,i]=istart+itmp\n",
    "delay = subset.time[istart+itmp].values-subset.time[istart+1].values\n",
    "coldwake_hrtomaxcold[j,i]=delay / np.timedelta64(1, 'h')\n",
    "print(coldwake_hrtomaxcold[j,i])\n",
    "for k in range(istart+itmp,tdim):\n",
    "    sst_change = subset.sst_prestorm[j,i]-subset.analysed_sst[k,j,i]\n",
    "    if sst_change>-0.2:\n",
    "        break\n",
    "delay = subset.time[k].values-subset.time[istart+1].values\n",
    "coldwake_recovery[j,i]=delay / np.timedelta64(1, 'h')\n",
    "print(coldwake_recovery[j,i].data)\n",
    "print(subset.sst_prestorm[j,i]-subset.analysed_sst[istart+itmp:,j,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_all.time[0])\n",
    "plt.subplot(131)\n",
    "plt.pcolormesh(ds_all.lon,ds_all.lat,ds_all.coldwake_max,vmin=-1,vmax=1)\n",
    "plt.plot(ds_storm_info.lon+360,ds_storm_info.lat,'w')\n",
    "plt.plot(ds_storm_info.lon[0]+360,ds_storm_info.lat[0],'r*')\n",
    "plt.subplot(132)\n",
    "plt.pcolormesh(subset.lon,subset.lat,subset.coldwake_max,vmin=-1,vmax=1)\n",
    "plt.subplot(133)\n",
    "plt.pcolormesh(coldwake_recovery/24,vmin=0,vmax=40)\n",
    "plt.colorbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,tdim):\n",
    "    storm_date = date_1858 + dt.timedelta(days=float(ds_storm_info.time[i]))  #create new time array that can be queried for year etc\n",
    "    print(storm_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.sst_prestorm[40,100].data\n",
    "i,j = 100,40\n",
    "storm_date = date_1858 + dt.timedelta(days=float(ds_all.closest_storm_time[j,i]))  #create new time array that can be queried for year etc\n",
    "storm_date64 = np.datetime64(storm_date)\n",
    "#print(subset.time)\n",
    "time_diff = subset.time-storm_date64\n",
    "storm_index = np.argmin(abs(time_diff)).data\n",
    "istart,iend = int(storm_index)-1,int(storm_index)+5\n",
    "if istart<0:\n",
    "    istart=0\n",
    "if iend>tdim:\n",
    "    iend=tdim\n",
    "coldwake_max[j,i] = (subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i]).min()\n",
    "itmp = np.argmin(subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i])\n",
    "print(itmp)\n",
    "print(subset.sst_prestorm[j,i].values,subset.analysed_sst[istart:iend,j,i].values)\n",
    "print(istart,iend)\n",
    "print(coldwake_max[j,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(subset.sst_prestorm[j,i]-subset.analysed_sst[istart:iend,j,i]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out2 = 'F:/data/tc_wakes/database/sst/'\n",
    "iyr_storm,inum_storm = 2003,2\n",
    "filename = dir_out2 + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_interpolated_track.nc'\n",
    "dsint=xr.open_dataset(filename)\n",
    "dsint.close()\n",
    "filename = dir_out2 + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_combined_data_all.nc'\n",
    "ds_all = xr.open_dataset(filename)\n",
    "ds_all.close()\n",
    "print(dsint.dims)\n",
    "print(ds_all.closest_storm_index.min(),ds_all.closest_storm_index.max())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all.spd.max('time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr=2003\n",
    "filename='F:/data/tc_wakes/ibtracks/year/Year.'+str(lyr)+'.ibtracs_wmo.v03r10.nc'\n",
    "ds_storm_info = xr.open_dataset(filename)\n",
    "ds_storm_info.close()\n",
    "ds_storm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test storm\n",
    "isave_mld_year = 0 #init MLD monthly data read flag\n",
    "for root, dirs, files in os.walk(dir_storm_info, topdown=False):\n",
    "    if root[len(dir_storm_info):len(dir_storm_info)+1]=='.':\n",
    "        continue\n",
    "    for name in files:\n",
    "        if not name.endswith('.nc'):\n",
    "            continue\n",
    "        filename=os.path.join(root, name)\n",
    "        print(filename[36:39],filename[31:35])\n",
    "        inum_storm=int(filename[36:39])\n",
    "        iyr_storm=int(filename[31:35])\n",
    "\n",
    "        \n",
    "        if iyr_storm!=2003:\n",
    "            continue\n",
    "        if inum_storm!=5:\n",
    "            continue\n",
    "#        if iyr_storm==2002 and inum_storm<9:\n",
    "#            continue\n",
    "        \n",
    "        \n",
    "#        if iyr_storm!=2007: # or iyr_storm<2003:\n",
    "#            continue\n",
    "        print(name,filename)\n",
    "        ds_storm_info = xr.open_dataset(filename)\n",
    "        lats = ds_storm_info.lat[0,:]\n",
    "        lons = ds_storm_info.lon[0,:]  #lons goes from 0 to 360\n",
    "        lons = (lons + 180) % 360 - 180 #put -180 to 180\n",
    "        dysince = ds_storm_info.time\n",
    "        ds_storm_info.close()\n",
    "        \n",
    "#make lat and lon of storm onto 25 km grid for below\n",
    "        lons = (((lons - .125)/.25+1).astype(int)-1)*.25+.125\n",
    "        lats = (((lats + 89.875)/.25+1).astype(int)-1)*.25-89.875\n",
    "        \n",
    "        iwrap=0\n",
    "#calculate size of box to get data in\n",
    "        minlon,maxlon = min(lons.values)-10, max(lons.values)+10\n",
    "        minlat,maxlat = min(lats.values)-10, max(lats.values)+10\n",
    "\n",
    "        ydim_storm = round((maxlat - minlat)/.25).astype(int)\n",
    "        new_lat_storm = np.linspace(minlat, maxlat, ydim_storm)\n",
    "        if (minlon<-90 and maxlon>=90) or (minlon<-180 and maxlon<0):  #this storm wraps  keep everythig 0 to 360 then wrap data at very end\n",
    "            iwrap = 1\n",
    "            lons2 = np.mod(lons, 360)\n",
    "            minlon, maxlon = min(lons2.values)-10, max(lons2.values)+10\n",
    "            xdim_storm = round((maxlon - minlon)/.25).astype(int)\n",
    "            new_lon_storm = np.linspace(minlon, maxlon, xdim_storm)\n",
    "        else:\n",
    "            xdim_storm = round((maxlon - minlon)/.25).astype(int)\n",
    "            new_lon_storm = np.linspace(minlon, maxlon, xdim_storm)\n",
    "\n",
    "        print(iwrap,minlon,maxlon)\n",
    "        print(iwrap,xdim_storm, new_lon_storm[:5],new_lon_storm[-5:])\n",
    "\n",
    "        \n",
    "        date_1858 = dt.datetime(1858,11,17,0,0,0) # start date is 11/17/1958\n",
    "        dims=lats.shape\n",
    "        tdim=dims[0]\n",
    "        tem_date=[0]*tdim #print(dysince.values)\n",
    "        for i in range(0,tdim):\n",
    "            tem_date[i]=date_1858+dt.timedelta(days=float(dysince[0,i].values))  #create new time array that can be queried for year etc\n",
    "        min_date = min(tem_date)+dt.timedelta(days=-5)\n",
    "        max_date = max(tem_date)+dt.timedelta(days=5)\n",
    "        minjdy = min_date.timetuple().tm_yday  #create new time array that can be queried for year etc\n",
    "        minyear =min_date.year #create new time array that can be queried for year etc\n",
    "        minmon =min_date.month #create new time array that can be queried for year etc\n",
    "        minday =min_date.day #create new time array that can be queried for year etc\n",
    "        maxjdy = max_date.timetuple().tm_yday  #create new time array that can be queried for year etc\n",
    "        maxyear =max_date.year  #create new time array that can be queried for year etc\n",
    "        print(minyear,minjdy,maxyear,maxjdy)\n",
    "        \n",
    "        dif = max(tem_date)-min(tem_date)\n",
    "        tdim=int(dif.days)+30             #calculate ssts for 30 days after storm\n",
    "\n",
    "        #print(tdim,xdim,ydim)            \n",
    "        filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_combined_data.nc'\n",
    "        ds_all = xr.open_dataset(filename,drop_variables=['uwnd','vwnd','dbss_obml','lhtfl','shtfl','tmp2m ','hum2m','analysed_sst_clim'])\n",
    "        ds_all.close()\n",
    "        \n",
    "#        ds_all = xr.merge([ds_storm_ccmp, ds_storm_mld, ds_storm_lhf, ds_storm_shf, ds_storm_ta, ds_storm_qa, ds_storm_sst])\n",
    "        if iwrap==1:\n",
    "            ds_all.coords['lon'] = np.mod(ds_all['lon'], 360)\n",
    "            ds_storm_info['lon'] = np.mod(ds_storm_info['lon'], 360)\n",
    "\n",
    "        #calculate mask\n",
    "        print('caluculating mask')\n",
    "        ds_mask = calculate_storm_mask(ds_all,lats,lons)\n",
    "        ds_all['storm_mask']=ds_mask['storm_mask']\n",
    "        #dist to storm\n",
    "        print('calculating dist')\n",
    "        dist,index,stime,position,ds_storm_interp = closest_dist(ds_all,ds_storm_info)\n",
    "        dtem=xr.DataArray(dist, coords={'lat': ds_mask.lat.values, 'lon':ds_mask.lon.values}, dims=('lat', 'lon'))\n",
    "        ds_all['dist_from_storm_km']=dtem\n",
    "        dtem=xr.DataArray(index, coords={'lat': ds_mask.lat.values, 'lon':ds_mask.lon.values}, dims=('lat', 'lon'))\n",
    "        ds_all['closest_storm_index']=dtem\n",
    "        dtem=xr.DataArray(stime, coords={'lat': ds_mask.lat.values, 'lon':ds_mask.lon.values}, dims=('lat', 'lon'))\n",
    "        ds_all['closest_storm_time']=dtem\n",
    "        dtem=xr.DataArray(position, coords={'lat': ds_mask.lat.values, 'lon':ds_mask.lon.values}, dims=('lat', 'lon'))\n",
    "        ds_all['side_of_storm']=dtem\n",
    "\n",
    "        \n",
    "        filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_combined__masking_data.nc'\n",
    "        ds_all.to_netcdf(filename)\n",
    "        print('out:',filename)\n",
    "        filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_interpolated_track.nc'\n",
    "        ds_storm_interp.to_netcdf(filename)\n",
    "        print('out:',filename)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_combined__masking_data2.nc'\n",
    "        ds_all.to_netcdf(filename)\n",
    "        print('out:',filename)\n",
    "        filename = dir_out + str(iyr_storm) + '/' + str(inum_storm).zfill(3) + '_interpolated_track2.nc'\n",
    "        ds_storm_interp.to_netcdf(filename)\n",
    "        print('out:',filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
